{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22de27f6-b2e2-48ce-9fa9-d9be2102ea89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS incremental_load.default.raw_upi_transactions_v1\n",
    "(\n",
    "    transaction_id STRING,\n",
    "    upi_id STRING,\n",
    "    merchant_id STRING,\n",
    "    txn_amount DOUBLE,\n",
    "    transaction_time TIMESTAMP,\n",
    "    txn_status STRING\n",
    ")\n",
    "USING DELTA\n",
    "TBLPROPERTIES (delta.enableChangeDataFeed = true)\n",
    "\"\"\")\n",
    "\n",
    "print(\"Table 'incremental_load.default.raw_upi_transactions_v1' has been created with CDC enabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc075e65-8c09-48df-8c2c-4bc13cc59ac9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"transaction_id\", StringType(), True), \n",
    "    StructField(\"upi_id\", StringType(), True),\n",
    "    StructField(\"merchant_id\", StringType(), True),\n",
    "    StructField(\"txn_amount\", DoubleType(), True),\n",
    "    StructField(\"transaction_time\", StringType(), True),\n",
    "    StructField(\"txn_status\", StringType(), True)\n",
    "])\n",
    "\n",
    "data_batch_1 = [\n",
    "    (\"txn_001\", \"upi_abc@bank\", \"m_001\", 100.0, \"2024-12-21 10:00:00\", \"initiated\"),\n",
    "    (\"txn_002\", \"upi_xyz@bank\", \"m_002\", 250.5, \"2024-12-21 10:05:00\", \"initiated\"),\n",
    "    (\"txn_003\", \"upi_pqr@bank\", \"m_003\", 75.0, \"2024-12-21 10:10:00\", \"initiated\")\n",
    "]\n",
    "\n",
    "data_batch_2 = [\n",
    "     (\"txn_001\", \"upi_abc@bank\", \"m_001\", 100.0, \"2024-12-21 10:15:00\", \"completed\"),\n",
    "    (\"txn_002\", \"upi_xyz@bank\", \"m_002\", 250.5, \"2024-12-21 10:20:00\", \"failed\"),\n",
    "    (\"txn_003\", \"upi_pqr@bank\", \"m_003\", 75.0, \"2024-12-21 10:25:00\", \"initiated\")\n",
    "]\n",
    "\n",
    "data_batch_3 = [\n",
    "     (\"txn_001\", \"upi_abc@bank\", \"m_001\", 100.0, \"2024-12-21 10:30:00\", \"refunded\"),\n",
    "    (\"txn_003\", \"upi_pqr@bank\", \"m_003\", 75.0, \"2024-12-21 10:35:00\", \"completed\")\n",
    "]\n",
    "\n",
    "mock_batches = [\n",
    "    # Batch 1: Initial insert\n",
    "    spark.createDataFrame(data_batch_1, schema),\n",
    "    # Batch 2: Update and insert\n",
    "    spark.createDataFrame(data_batch_2, schema),\n",
    "    # Batch 3: Update and refunds\n",
    "    spark.createDataFrame(data_batch_3, schema),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b77f930f-5b42-45d3-97f4-0e03406318e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def merge_into_delta_table(delta_table_name: str, batch_df):\n",
    "    delta_table = DeltaTable.forName(spark, delta_table_name)\n",
    "\n",
    "    delta_table.alias(\"target\").merge(\n",
    "        batch_df.alias(\"source\"),\n",
    "        \"target.transaction_id = source.transaction_id\" \n",
    "    ).whenMatchedUpdate(\n",
    "        set={\n",
    "            \"upi_id\": \"source.upi_id\",\n",
    "            \"merchant_id\": \"source.merchant_id\",\n",
    "            \"txn_amount\": \"source.txn_amount\",\n",
    "            \"transaction_time\": \"source.transaction_time\",\n",
    "            \"txn_status\": \"source.txn_status\"\n",
    "        }\n",
    "    ).whenNotMatchedInsertAll() \\\n",
    "    .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "727c6c3b-64c7-4a13-b9df-b7daf7a97abb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merge_into_delta_table(\"incremental_load.default.raw_upi_transactions_v1\", mock_batches[2])\n",
    "print(f\"Batch processed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "upi_transactions_mock_generate",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
